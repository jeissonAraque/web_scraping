name: Web Scraping Workflow

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  scraping-job:
    runs-on: ubuntu-latest

    steps:
    # 1. Configura el repositorio
    - name: Checkout repository
      uses: actions/checkout@v3

    # 2. Configura Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    # 3. Instala las dependencias
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install selenium webdriver-manager beautifulsoup4 pandas requests

    # 4. Descarga y configura ChromeDriver
    - name: Set up ChromeDriver
      uses: nanasess/setup-chromedriver@v1
      with:
        chromedriver-version: latest

    # 5. Descarga y configura Google Chrome
    - name: Install Google Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable

    # 6. Ejecuta el script de scraping
    - name: Run web scraping script
      run: |
        python -m pip install notebook
        jupyter nbconvert --to script Araque_Jeisson_Analizando.ipynb
        python path/to/your_notebook.py
